{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n",
    "\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, DateType, LongType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('./dl.cfg'))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create spark session with hadoop-aws package\n",
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create aws session \n",
    "session = boto3.session.Session()\n",
    "s3_client = session.client('s3') # a raw, low-level calls made by service clients.\n",
    "s3_resource = session.resource('s3') # a higher-level abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Song Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the song data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket =  s3_resource.Bucket(\"udacity-dend\")\n",
    "# for obj in Bucket.objects.filter(Prefix=\"song_data\"):\n",
    "#     print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"artist_id\":\"ARA23XO1187B9AF18F\",\"artist_latitude\":40.57885,\"artist_location\":\"Carteret, New Jersey\",\"artist_longitude\":-74.21956,\"artist_name\":\"The Smithereens\",\"duration\":192.522,\"num_songs\":1,\"song_id\":\"SOKTJDS12AF72A25E5\",\"title\":\"Drown In My Own Tears (24-Bit Digitally Remastered 04)\",\"year\":0}\n"
     ]
    }
   ],
   "source": [
    "song_json =s3_client.get_object(Bucket='udacity-dend', Key='song_data/A/A/A/TRAAAUC128F428716F.json')\n",
    "song_text = song_json['Body'].read().decode('utf-8')\n",
    "print(song_text)\n",
    "# song_df = pd.read_json(song_json['Body'], lines=True)\n",
    "# song_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw song data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawSongSchema = StructType([\n",
    "    StructField('artist_id', StringType()),\n",
    "    StructField('artist_latitude', DoubleType()),\n",
    "    StructField('artist_location', StringType()),\n",
    "    StructField('artist_longitude', DoubleType()),\n",
    "    StructField('artist_name', StringType()),\n",
    "    StructField('duration', DoubleType()),\n",
    "    StructField('num_songs', IntegerType()),\n",
    "    StructField('song_id', StringType()),\n",
    "    StructField('title', StringType()),\n",
    "    StructField('year', IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "+------------------+---------------+--------------------+----------------+------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|     artist_location|artist_longitude|       artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+--------------------+----------------+------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARTC1LV1187B9A4858|        51.4536|Goldsmith's Colle...|        -0.01802|The Bonzo Dog Band|301.40036|        1|SOAFBCP12A8C13CC7D|King Of Scurf (20...|1972|\n",
      "|ARA23XO1187B9AF18F|       40.57885|Carteret, New Jersey|       -74.21956|   The Smithereens|  192.522|        1|SOKTJDS12AF72A25E5|Drown In My Own T...|   0|\n",
      "|ARSVTNL1187B992A91|       51.50632|     London, England|        -0.12714|     Jonathan King|129.85424|        1|SOEKAZG12AB018837E|I'll Slap Your Fa...|2001|\n",
      "+------------------+---------------+--------------------+----------------+------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df = spark.read.json(\"s3a://udacity-dend/song_data/A/A/A\",  schema=RawSongSchema)\n",
    "\n",
    "song_df.printSchema()\n",
    "song_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries on raw song data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOAFBCP12A8C13CC7D|King Of Scurf (20...|ARTC1LV1187B9A4858|1972|301.40036|\n",
      "|SOKTJDS12AF72A25E5|Drown In My Own T...|ARA23XO1187B9AF18F|   0|  192.522|\n",
      "|SOEKAZG12AB018837E|I'll Slap Your Fa...|ARSVTNL1187B992A91|2001|129.85424|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df.createOrReplaceTempView(\"song_raw\")\n",
    "spark.sql(\"SELECT song_id, title, artist_id, year, duration FROM song_raw limit 3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------------------+---------------+----------------+\n",
      "|         artist_id|       artist_name|     artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+------------------+--------------------+---------------+----------------+\n",
      "|ARTC1LV1187B9A4858|The Bonzo Dog Band|Goldsmith's Colle...|        51.4536|        -0.01802|\n",
      "|ARA23XO1187B9AF18F|   The Smithereens|Carteret, New Jersey|       40.57885|       -74.21956|\n",
      "|ARSVTNL1187B992A91|     Jonathan King|     London, England|       51.50632|        -0.12714|\n",
      "+------------------+------------------+--------------------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT artist_id, artist_name,artist_location, artist_latitude, artist_longitude \n",
    "FROM song_raw limit 3\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write songs table to parquet files partitioned by year and artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = spark.sql(\"\"\"\n",
    "SELECT song_id, title, artist_id, year, duration FROM song_raw\n",
    "WHERE song_id is not null\n",
    "\"\"\")\n",
    "song_df.write.parquet(\"s3a://mysparkify/data/song\", mode=\"overwrite\", partitionBy=['year','artist_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write artists table to parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT artist_id, artist_name,artist_location, artist_latitude, artist_longitude \n",
    "FROM song_raw \n",
    "WHERE artist_id is not null\n",
    "\"\"\").write.parquet(\"s3a://mysparkify/data/artists\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the songs, artists table stored in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+---------+----+------------------+\n",
      "|           song_id|               title| duration|year|         artist_id|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|SORRNOC12AB017F52B|The Last Beat Of ...|337.81506|2004|ARSZ7L31187FB4E610|\n",
      "|SOIGICF12A8C141BC5|        Game & Watch|580.54485|2004|AREWD471187FB49873|\n",
      "|SOIGHOD12A8C13B5A1|        Indian Angel|171.57179|2004|ARY589G1187B9A9F4E|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM parquet.`s3a://mysparkify/data/song` where year = 2004\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|         artist_id|         artist_name|     artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|ARTC1LV1187B9A4858|  The Bonzo Dog Band|Goldsmith's Colle...|        51.4536|        -0.01802|\n",
      "|ARA23XO1187B9AF18F|     The Smithereens|Carteret, New Jersey|       40.57885|       -74.21956|\n",
      "|ARSVTNL1187B992A91|       Jonathan King|     London, England|       51.50632|        -0.12714|\n",
      "|AR73AIO1187B9AD57B|   Western Addiction|   San Francisco, CA|       37.77916|      -122.42005|\n",
      "|ARXQBR11187B98A2CC|Frankie Goes To H...|  Liverpool, England|           null|            null|\n",
      "|ARSZ7L31187FB4E610|           Devotchka|          Denver, CO|       39.74001|      -104.99226|\n",
      "|AR10USD1187B99F3F1|Tweeterfriendly M...|Burlington, Ontar...|           null|            null|\n",
      "|ARZ5H0P1187B98A1DD|          Snoop Dogg|      Long Beach, CA|       33.76672|       -118.1924|\n",
      "|AR1KTV21187B9ACD72|            Cristina|     California - LA|       34.05349|      -118.24532|\n",
      "|ARCLYBR1187FB53913|          Neal Schon|       San Mateo, CA|       37.54703|      -122.31483|\n",
      "|ARBZIN01187FB362CC|        Paris Hilton|                  27|        1.32026|       103.78871|\n",
      "|AR5LMPY1187FB573FE|   Chaka Khan_ Rufus|         Chicago, IL|       41.88415|       -87.63241|\n",
      "|ARY589G1187B9A9F4E|         Talkdemonic|        Portland, OR|       45.51179|      -122.67563|\n",
      "|ARGE7G11187FB37E05|        Cyndi Lauper|        Brooklyn, NY|           null|            null|\n",
      "|ARMJAGH1187FB546F3|        The Box Tops|         Memphis, TN|       35.14968|       -90.04892|\n",
      "|AR0MWD61187B9B2B12|International Noi...|                    |           null|            null|\n",
      "|AR1C2IX1187B99BF74|     Broken Spindles|                    |           null|            null|\n",
      "|AR9Q9YC1187FB5609B|    Quest_ Pup_ Kevo|          New Jersey|           null|            null|\n",
      "|ARKYKXP11F50C47A6A|    The Supersuckers|                    |           null|            null|\n",
      "|ARC1IHZ1187FB4E920|        Jamie Cullum|                    |           null|            null|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM parquet.`s3a://mysparkify/data/artists`\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Log Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the log data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket =  s3_resource.Bucket(\"udacity-dend\")\n",
    "# for obj in Bucket.objects.filter(Prefix=\"log_data\"):\n",
    "#     print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"artist\":null,\"auth\":\"Logged In\",\"firstName\":\"Walter\",\"gender\":\"M\",\"itemInSession\":0,\"lastName\":\"Frye\",\"length\":null,\"level\":\"free\",\"location\":\"San Francisco-Oakland-Hayward, CA\",\"method\":\"GET\",\"page'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_file_object =s3_client.get_object(Bucket='udacity-dend', Key='log_data/2018/11/2018-11-01-events.json')\n",
    "file_content = log_file_object['Body'].read().decode('utf-8')\n",
    "file_content[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = s3_client.get_object(Bucket='udacity-dend', Key='log_json_path.json')\n",
    "# text = result['Body'].read().decode('utf-8')\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw song data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RawLogSchema = StructType([\n",
    "    StructField('artist', StringType()),\n",
    "    StructField('auth', StringType()),\n",
    "    StructField('firstName', StringType()),\n",
    "    StructField('gender', StringType()),\n",
    "    StructField('itemInSession', IntegerType()),\n",
    "    StructField('lastName', StringType()),\n",
    "    StructField('length', DoubleType()),\n",
    "    StructField('level', StringType()),\n",
    "    StructField('location', StringType()),\n",
    "    StructField('method', StringType()),    \n",
    "    StructField('page', StringType()),\n",
    "    StructField('registration', StringType()),\n",
    "    StructField('sessionId', IntegerType()),\n",
    "    StructField('song', StringType()),\n",
    "    StructField('status', IntegerType()),\n",
    "    StructField('ts', LongType()),\n",
    "    StructField('userAgent', StringType()),\n",
    "    StructField('userId', StringType())\n",
    "])\n",
    "# registration, userId dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.read.json(\"s3a://udacity-dend/log_data/2018/11/2018-11-01-events.json\",  schema=RawLogSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = log_df.select(\"*\").where(\"page = 'NextSong'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add songplay_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_df = log_df.select(\"*\").withColumn(\"songplay_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------+\n",
      "|songplay_id| artist|firstName|\n",
      "+-----------+-------+---------+\n",
      "|          0|   null|   Walter|\n",
      "|          1|   null|   Kaylee|\n",
      "|          2|Des'ree|   Kaylee|\n",
      "+-----------+-------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"songplay_id\", \"artist\", \"firstName\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ts to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|           ts|\n",
      "+-------------+\n",
      "|1541105830796|\n",
      "|1541106106796|\n",
      "|1541106106796|\n",
      "+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ts\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@udf(TimestampType())\n",
    "def convert_unix_time_udf(x):\n",
    "    if x:\n",
    "        return pd.to_datetime(x,unit='ms')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_df= log_df.withColumn(\"start_time\", convert_unix_time_udf(\"ts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|           ts|          start_time|\n",
      "+-------------+--------------------+\n",
      "|1541105830796|2018-11-01 20:57:...|\n",
      "|1541106106796|2018-11-01 21:01:...|\n",
      "|1541106106796|2018-11-01 21:01:...|\n",
      "+-------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ts\", \"start_time\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf = log_df.toPandas()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     39|    Walter|     Frye|     M| free|\n",
      "|      8|    Kaylee|  Summers|     F| free|\n",
      "|      8|    Kaylee|  Summers|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.createOrReplaceTempView(\"log_raw\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT userId as user_id,\n",
    "firstName as first_name,\n",
    "lastName as last_name,\n",
    "gender,\n",
    "level\n",
    "FROM log_raw\n",
    "limit 3\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "select user_id, first_name, last_name, gender, level\n",
    "from\n",
    "(SELECT userId as user_id, firstName as first_name, lastName as last_name, gender, level\n",
    "FROM log_raw\n",
    "WHERE userId is not null)\n",
    "group by 1,2,3,4,5\n",
    "\"\"\").write.parquet(\"s3a://mysparkify/data/users\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----+-----+----+---+----+-------+\n",
      "|           ts|          start_time|year|month|week|day|hour|weekday|\n",
      "+-------------+--------------------+----+-----+----+---+----+-------+\n",
      "|1541105830796|2018-11-01 20:57:...|2018|   11|  44|  1|  20|    Thu|\n",
      "|1541106106796|2018-11-01 21:01:...|2018|   11|  44|  1|  21|    Thu|\n",
      "|1541106106796|2018-11-01 21:01:...|2018|   11|  44|  1|  21|    Thu|\n",
      "+-------------+--------------------+----+-----+----+---+----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.select(\"ts\", \"start_time\", \\\n",
    "                  year(\"start_time\").alias(\"year\"),\\\n",
    "                  month(\"start_time\").alias(\"month\"),\\\n",
    "                  weekofyear(\"start_time\").alias(\"week\"),\\\n",
    "                  dayofmonth(\"start_time\").alias(\"day\"),\\\n",
    "                  hour(\"start_time\").alias(\"hour\"),\\\n",
    "                  date_format(\"start_time\",'E').alias(\"weekday\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|          start_time|hour|day|week|month|year|weekday|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-01 21:55:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:08:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 22:23:...|  22|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:42:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:05:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:01:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:52:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:11:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 20:57:...|  20|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:50:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:02:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:24:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:17:...|  21|  1|  44|   11|2018|    Thu|\n",
      "|2018-11-01 21:28:...|  21|  1|  44|   11|2018|    Thu|\n",
      "+--------------------+----+---+----+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select start_time, hour, day, week, month, year, weekday\n",
    "from\n",
    "(SELECT start_time, hour(start_time) as hour, dayofmonth(start_time) as day,\n",
    "weekofyear(start_time) as week, month(start_time) as month, \n",
    "year(start_time) as year, date_format(start_time,'E') as weekday\n",
    "FROM log_raw\n",
    "WHERE start_time is not null)\n",
    "group by 1,2,3,4,5,6,7\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_df.createOrReplaceTempView(\"log_raw\")\n",
    "spark.sql(\"\"\"\n",
    "select start_time, hour, day, week, month, year, weekday\n",
    "from\n",
    "(SELECT start_time, hour(start_time) as hour, dayofmonth(start_time) as day,\n",
    "weekofyear(start_time) as week, month(start_time) as month, \n",
    "year(start_time) as year, date_format(start_time,'E') as weekday\n",
    "FROM log_raw\n",
    "WHERE start_time is not null)\n",
    "group by 1,2,3,4,5,6,7\n",
    "\"\"\").write.parquet(\"s3a://mysparkify/data/time\", mode=\"overwrite\", partitionBy='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## songplays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_df = spark.read.parquet(\"s3a://mysparkify/data/song\")\n",
    "artists_df = spark.read.parquet(\"s3a://mysparkify/data/artists\")\n",
    "\n",
    "song_df.createOrReplaceTempView(\"songs\")\n",
    "artists_df.createOrReplaceTempView(\"artists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'auth', 'firstName', 'gender', 'itemInSession', 'lastName',\n",
       "       'length', 'level', 'location', 'method', 'page', 'registration',\n",
       "       'sessionId', 'song', 'status', 'ts', 'userAgent', 'userId',\n",
       "       'songplay_id', 'start_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.toPandas().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT songplay_id, start_time, b.song_id as song_id, c.artist_id as artist_id,\n",
    "userId as user_id,\n",
    "sessionId as session_id,\n",
    "location,\n",
    "level,\n",
    "userAgent as user_agent\n",
    "FROM log_raw a\n",
    "left join songs b\n",
    "on a.song = b.title\n",
    "left join artists c\n",
    "on a.artist = c.artist_name\n",
    "\"\"\").write.parquet(\"s3a://mysparkify/data/songplays\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the users, time, songplays table stored in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     88|  Mohammad|Rodriguez|     M| free|\n",
      "|     88|  Mohammad|Rodriguez|     M| paid|\n",
      "|     75|    Joseph|Gutierrez|     M| free|\n",
      "|     69|  Anabelle|  Simpson|     F| free|\n",
      "|     11| Christian|   Porter|     F| free|\n",
      "|     53|   Celeste| Williams|     F| free|\n",
      "|     77| Magdalene|   Herman|     F| free|\n",
      "|     89|   Kynnedi|  Sanchez|     F| free|\n",
      "|     61|    Samuel| Gonzalez|     M| free|\n",
      "|     45|  Dominick|   Norris|     M| free|\n",
      "|      2|   Jizelle| Benjamin|     F| free|\n",
      "|     16|     Rylan|   George|     M| free|\n",
      "|     90|    Andrea|   Butler|     F| free|\n",
      "|     36|   Matthew|    Jones|     M| free|\n",
      "|     72|    Hayden|    Brock|     F| paid|\n",
      "|     40|    Tucker| Garrison|     M| free|\n",
      "|     28|  Brantley|     West|     M| free|\n",
      "|      7|    Adelyn|   Jordan|     F| free|\n",
      "|     64|    Hannah|  Calhoun|     F| free|\n",
      "|     52|  Theodore|    Smith|     M| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM parquet.`s3a://mysparkify/data/users`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|          start_time|hour|day|week|weekday|year|month|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-15 11:40:...|  16| 15|  46|    Thu|2018|   11|\n",
      "|2018-11-15 12:03:...|  17| 15|  46|    Thu|2018|   11|\n",
      "|2018-11-15 12:25:...|  17| 15|  46|    Thu|2018|   11|\n",
      "|2018-11-13 22:26:...|   3| 14|  46|    Wed|2018|   11|\n",
      "|2018-11-14 07:26:...|  12| 14|  46|    Wed|2018|   11|\n",
      "|2018-11-14 08:12:...|  13| 14|  46|    Wed|2018|   11|\n",
      "|2018-11-28 11:32:...|  16| 28|  48|    Wed|2018|   11|\n",
      "|2018-11-28 16:20:...|  21| 28|  48|    Wed|2018|   11|\n",
      "|2018-11-28 18:57:...|  23| 28|  48|    Wed|2018|   11|\n",
      "|2018-11-04 23:40:...|   4|  5|  45|    Mon|2018|   11|\n",
      "|2018-11-05 10:31:...|  15|  5|  45|    Mon|2018|   11|\n",
      "|2018-11-13 05:17:...|  10| 13|  46|    Tue|2018|   11|\n",
      "|2018-11-13 10:54:...|  15| 13|  46|    Tue|2018|   11|\n",
      "|2018-11-13 15:00:...|  20| 13|  46|    Tue|2018|   11|\n",
      "|2018-11-13 16:12:...|  21| 13|  46|    Tue|2018|   11|\n",
      "|2018-11-30 10:10:...|  15| 30|  48|    Fri|2018|   11|\n",
      "|2018-11-30 11:17:...|  16| 30|  48|    Fri|2018|   11|\n",
      "|2018-11-30 12:22:...|  17| 30|  48|    Fri|2018|   11|\n",
      "|2018-11-16 05:47:...|  10| 16|  46|    Fri|2018|   11|\n",
      "|2018-11-16 18:34:...|  23| 16|  46|    Fri|2018|   11|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM parquet.`s3a://mysparkify/data/time`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+---------+-------+----------+--------------------+-----+--------------------+\n",
      "|songplay_id|          start_time|song_id|artist_id|user_id|session_id|            location|level|          user_agent|\n",
      "+-----------+--------------------+-------+---------+-------+----------+--------------------+-----+--------------------+\n",
      "|          0|2018-11-14 19:30:...|   null|     null|     26|       583|San Jose-Sunnyval...| free|\"Mozilla/5.0 (X11...|\n",
      "|          1|2018-11-14 19:41:...|   null|     null|     26|       583|San Jose-Sunnyval...| free|\"Mozilla/5.0 (X11...|\n",
      "|          2|2018-11-14 19:45:...|   null|     null|     26|       583|San Jose-Sunnyval...| free|\"Mozilla/5.0 (X11...|\n",
      "+-----------+--------------------+-------+---------+-------+----------+--------------------+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM parquet.`s3a://mysparkify/data/songplays`\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
